data:
  _target_: src.data.datamodule.MyDataModule

  datasets:
    train:
      _target_: src.data.dataset.MyDataset
      name: YourTrainDatasetName
      path: ${oc.env:YOUR_TRAIN_DATASET_PATH}

    val:
      - _target_: src.data.dataset.MyDataset
        name: YourValDatasetName
        path: ${oc.env:YOUR_VAL_DATASET_PATH}

    test:
      - _target_: src.data.dataset.MyDataset
        name: YourTestDatasetName
        path: ${oc.env:YOUR_TEST_DATASET_PATH}

  num_workers:
    train: 8
    val: 4
    test: 4

  batch_size:
    train: 32
    val: 16
    test: 16

module:
  _target_: src.modules.nn.MyModel

  optimizer:
    #  Adam-oriented deep learning
    _target_: torch.optim.Adam
    #  These are all default parameters for the Adam optimizer
    lr: 0.001
    betas: [ 0.9, 0.999 ]
    eps: 1e-08
    weight_decay: 0

  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    T_0: 10
    T_mult: 2
    eta_min: 0 # min value for the lr
    last_epoch: -1
    verbose: True
